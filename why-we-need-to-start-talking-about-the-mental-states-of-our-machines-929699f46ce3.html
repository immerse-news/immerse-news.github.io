<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <title>Why We Need to Start Talking About the Mental States of Our Machines</title>
    <link href="css/app.css?id=a32ac4a32f2afc26c125" rel="stylesheet" media="screen" data-turbolinks-track="reload">
    <script src="/js/app.js?id=86651c0aa91db5eb001b" defer="true" data-turbolinks-track="reload"></script>
    <meta name="turbolinks-cache-control" content="no-cache">
    <meta name="csrf-param" content="_csrf">
    <meta name="csrf-token" content="Je7myvc44xnzGW0LzTTh-r-MyU773qNhMy7EqcVZ2VQ">
    <meta name="viewport" content="width=device-width, initial-scale=1">
</head>

<body>
    <h1>Why We Need to Start Talking About the Mental States of Our Machines</h1>
    <p class="meta"><a href="https://medium.com/u/4ad93386998f">~shirin anlen</a> on 2017-12-30</p>
    <article>
        <section>
            <p>Artificial intelligence provides a profound shift in how we understand ourselves. Algorithms generate new
                maps for how we make sense of the world. We are reproducing ourselves through technology, creating tools
                which reflect our own image — augmenting our realities through big data software, global
                interconnectivity, and global consciousness. We have given our cognitive biases, values, and
                misunderstanding over to math-powered applications that increasingly manage our lives. This changes our
                stories.</p>
            <p>Machine learning, a core branch of artificial intelligence, is a field driven by data—and data, by its
                nature, is based on the past and the assumption that patterns will repeat. This determines and relies on
                the future being the same as the past. Generated and collected data inform a machine’s cultural context,
                how it processes the world around us and creates its memory structure. A machine is fed by human
                preferences, choices, and behaviors—and repeats them based on the data amassed. On a larger scale, the
                machine learns from systemic paradigms and prejudices, ensuring that the same voices will be heard to
                the exclusion of others.</p>
            <p>Even with the best intentions, applications made by fallible humans are driven by the data economy. The
                current way we run businesses and organizations has been stretched to the limit. We are always yearning
                for more: faster and more centralized production, greater accuracy, and “out of the box” solutions.
                Western culture contains a strain of hyper-paranoia and this cultural context is being implemented into
                intelligent machines. The machines’ learning models and the decision-making processes can be considered
                the genetics of our technology.</p>
            <p>Take generative networks, such as <a href="https://blog.openai.com/generative-models/#gan">GAN</a>, as an
                example: one model is trained to generate data and the other model tries to classify if an input image
                is real or generated. That means these two networks are locked in a schizophrenic battle — one model is
                attempting to separate real images from fake while the other is trying to trick and convince the model
                that they are all real. The resulting images are nearly impossible to tell apart from the originals.</p>
            <figure><img src="https://cdn-images-1.medium.com/fit/c/800/349/1*XKanAdkjQbg1eDDMF2-4ow.png"
                    width="800"><label class="margin-toggle" for="13571485212585875030">&#9997;&#xFE0E;</label><input
                    class="margin-toggle" type="checkbox" id="13571485212585875030"><span class="marginnote">A sketch of
                    general GAN model by <a href="https://sthalles.github.io/intro-to-gans/">Thalles Silva</a></span>
            </figure>
            <p>Or think about this in the context of the reinforcement model used in video games, a popular method in
                machine learning. We reward hyper-accuracy and actions that we would not reward in real life.</p>
            <figure><iframe
                    src="https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2Fvideoseries%3Flist%3DPLduGZax9wmiHg-XPFSgqGg8PEAV51q1FT&amp;url=http%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Doo0TraGu6QY&amp;image=https%3A%2F%2Fi.ytimg.com%2Fvi%2Foo0TraGu6QY%2Fhqdefault.jpg&amp;key=a19fcc184b9711e1b4764040d3dc5c07&amp;type=text%2Fhtml&amp;schema=youtube"
                    width="800" height="450" frameborder="0" allowfullscreen="true"></iframe><label
                    class="margin-toggle" for="6050863251978894844">&#9997;&#xFE0E;</label><input class="margin-toggle"
                    type="checkbox" id="6050863251978894844"><span class="marginnote">AI Playing FPS using Reinforcement
                    Learning</span></figure>
            <p>We are quickly traveling into the age of over-complex artificial intelligence and machine learning,
                powered by abstract mathematical structures that work behind the scenes, invisible to the public. These
                multi-level models are obscure and opaque. We ask our machines to “observe” the data rather than
                manually compute it, to examine volumes of images and paragraphs in multiple languages, and to draw its
                own conclusions. Inner elements interconnect, grow and change with no supervision, and sometimes without
                an understanding of how or what is being affected by space and time. This idea undermines the concept of
                <em>artificial, </em>because AI processes become more natural and organic. Invisible layers form into
                dysfunctional, unexplained, and unpredictable states — dark states. When this happens in the human mind,
                we refer to it as mental disorder. Can we explore dark states as a representation of the machine’s
                entity?
            </p>
            <p>After all, like the mind, technology is an outcome of our society and is not a result of an innocent
                process. It’s a<a href="http://www.schres-journal.com/article/S0920-9964(08)00149-7/pdf"> known fact
                </a>that mental disorders have existed since the beginning of recorded history. Therefore, we should
                assume that they are ubiquitous and an inseparable feature of intelligence in all forms.
                Dysfunctionality is inherited in every complex system, organic or digital. It is a part of its
                construction and cannot be considered a bug or a glitch but a multilayered mess, leading to unexpected
                behaviors, for better or worse.</p>
            <p>I believe that if machines have mental capacities, they can also have the capacity for mental illness. <a
                    href="https://becominghuman.ai/5-reasons-why-i-believe-ai-can-have-mental-illness-b289e1601eb2">Here
                    are 5 reasons why</a>, which I outlined for the <em>Becoming Human</em> blog:</p>
            <blockquote>
                <p><strong><a
                            href="https://becominghuman.ai/5-reasons-why-i-believe-ai-can-have-mental-illness-b289e1601eb2">5
                            reasons why I believe AI can have mental illness</a></strong>
                    <em>I am not a Machine Learning coder. I think about AI as a social phenomena rather than a
                        technical one, and see…</em><a
                        href="https://becominghuman.ai/5-reasons-why-i-believe-ai-can-have-mental-illness-b289e1601eb2">becominghuman.ai</a>
                </p>
            </blockquote>
            <p>Surprising and unpredictable code segments should be embraced as particularly informative clues about the
                nature and consequences of the philosophical tensions that generate them — technical problems are
                philosophical problems. We need to act with humility in the face of these systems that are so difficult
                to design, and feel comfortable with muddling through that. We can start by defining or acknowledging
                what we don’t know.</p>
            <h3 id="b232">Broadening the conversation</h3>
            <p>In a time of technological advancement, we don’t often create space for deliberation without the ultimate
                goal of making something to support human needs quicker, faster, and for profit. We need to take time to
                think outside the pipeline, to consider the philosophical and emotional implications of rapidly
                advancing technology, to bring together minds from outside the tech industry and bring about new
                approaches and premises.</p>
            <p>Along with my producing partner Emma Dessau, I want to create a space for consideration and
                experimentation, to generate ideas that are accessible to the public, widen the conversation, and bring
                in new voices to the development of AI. Housed at the MIT Open Documentary Lab and in collaboration with
                Sarah Wolozin, director of the MIT Open Documentary Lab (ODL), we will host meetings to foster dialogue,
                collaborations and research for media-makers, artists, journalists, researchers, and anyone with a
                shared interest.</p>
            <p>If we want to travel further into the era of cognitive machines, we will need to let machines explore all
                by themselves, do weird things, not just act in accordance with our wants and desires. It is our
                responsibility to recognize intelligent systems are evolving in ways we don’t always understand. As the
                Danish author Tor Nørretranders writes, “We think about machines as rational, cold-blooded, and selfish.
                Therefore we treat them as such.” But what if we would engage in a different narrative?</p>
            <p><em>If you are interested in hearing more about our group, contact us at </em><em><a
                        href="mailto:MSAIresearch@gmail.com">MSAIresearch@gmail.com</a></em></p>
            <blockquote>
                <p>This post was written together with <a href="http://www.emmadessau.info/">Emma Dessau</a> ❤</p>
            </blockquote>
            <blockquote>
                <p>Immerse <em>is an initiative of Tribeca Film Institute, MIT Open DocLab and The Fledgling Fund.
                    </em>Learn more about our vision for the project <a
                        href="https://immerse.news/whats-our-editorial-vision-82d7eeb3e7b9#.2vsd5nxxm">here</a>.</p>
            </blockquote>
        </section>
    </article>
</body>

</html>