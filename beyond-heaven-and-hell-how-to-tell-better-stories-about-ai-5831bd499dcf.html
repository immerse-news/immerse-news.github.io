<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <title>Beyond Heaven and Hell: How to tell better stories about AI</title>
    <link href="css/app.css?id=a32ac4a32f2afc26c125" rel="stylesheet" media="screen" data-turbolinks-track="reload">
    <script src="/js/app.js?id=86651c0aa91db5eb001b" defer="true" data-turbolinks-track="reload"></script>
    <meta name="turbolinks-cache-control" content="no-cache">
    <meta name="csrf-param" content="_csrf">
    <meta name="csrf-token" content="tzdQrEj0xJiHJq3kIawqwWJLvwOXUiNjoqjsXHMUOx4">
    <meta name="viewport" content="width=device-width, initial-scale=1">
</head>

<body>
    <h1>Beyond Heaven and Hell: How to tell better stories about AI</h1>
    <p class="meta"><a href="https://medium.com/u/ebdb5a796592">Immerse</a> on 2018-03-20</p>
    <article>
        <section>
            <h3 id="ada0">An Immerse <a href="https://immerse.news/deep-reads-cda63458cca2">response</a></h3>
            <p><em>by Joanna Zylinska</em></p>
            <p>What is most interesting about Isaac Asimov’s famous “Three Laws of Robotics,” now frequently evoked in
                the context of research into AI, is not so much the codification of behavior they prescribe to his
                narrative creations. What is most interesting, for me at least, is the fact that his “robot ethics” is
                part of fiction.</p>
            <figure><img src="https://cdn-images-1.medium.com/fit/c/625/946/1*l0A176zv5vZLBy_Enh68tw.png"
                    width="625"><label class="margin-toggle" for="10862164220640835750">&#9997;&#xFE0E;</label><input
                    class="margin-toggle" type="checkbox" id="10862164220640835750"><span class="marginnote"></span>
            </figure>
            <h3 id="0e01"><strong>Asimov’s Three Laws of Robotics:</strong></h3>
            <blockquote>
                <p>A robot may not injure a human being or, through inaction, allow a human being to come to harm.</p>
            </blockquote>
            <blockquote>
                <p>A robot must obey orders given it by human beings except where such orders would conflict with the
                    First Law.</p>
            </blockquote>
            <blockquote>
                <p>A robot must protect its own existence as long as such protection does not conflict with the First or
                    Second Law.</p>
            </blockquote>
            <p>Developed in a number of short stories and published in the 1950 collection, <em>I Robot</em>, Asimov’s
                ethical precepts are somewhat mechanical, reductive and naively humanist. Like many other forms of
                deontological (i.e. normative) moral theories, they are an elegantly-designed ethical system that will
                ultimately fail because glitchy humans will at some point — through stupidity, malice, or sheer
                curiosity — introduce errors into it.</p>
            <p>Yet Asimov was no moral philosopher and so to extricate his laws into a stand-alone moral proposal is to
                do a disservice to the imagination and creative potential of his stories. What needs commanding instead
                is Asimov’s very gesture of <em>doing ethics as/in fiction</em>, or even his implicit proposition that
                ethical deliberation is best served by stories — rather than precepts or commandments.</p>
            <p>This is why I want to suggest that the most creative — and most needed — way in which storytellers can
                use AI is by <em>telling better stories about AI</em>, while also <em>imagining better ways of living
                    with AI</em>.</p>
            <p>Reflecting on the nature of this double “better” would be the crux of such storytelling. Mobilizing the
                tools of imagination, narrative, metaphor, parable, and irony, storytellers can perhaps begin by blowing
                some much-needed cool air on the heat and hype around AI currently emitting from Silicon Valley.</p>
            <p>To propose this is not to embrace a technophobic position or promote a return to narrative forms of
                yesteryear: detached, enclosed, single-medium based. It is rather to encourage storytellers to use their
                <em>technical</em> apparatus with a view to exposing the blind spots behind the current AI discourse.
                Storytelling as a technical activity can thus channel the Greek origins of the term <em>tekhnē</em>,
                referring as it does both to technical assemblages such as computers, databases, and neural nets and,
                more crucially perhaps, to the very process of bringing-forth, or creation.
            </p>
            <p>“Intelligence” itself is something of a blind spot in AI, with the field’s foundational concept either
                being taken for granted without too much interrogation or molded at will and then readjusted, depending
                on the direction the research has taken. Having moved away from the seemingly impossible desire to
                develop Artificial General Intelligence modeled on the human brain, researchers have recently
                repositioned AI as a sophisticated agent of pattern recognition.</p>
            <figure><img src="https://cdn-images-1.medium.com/fit/c/206/305/1*xrLLxshT46vlLi8H6_eH1g.png"
                    width="206"><label class="margin-toggle" for="10862164220640835750">&#9997;&#xFE0E;</label><input
                    class="margin-toggle" type="checkbox" id="10862164220640835750"><span class="marginnote"></span>
            </figure>
            <p>AI today is thus a post-cyberpunk incarnation of William Gibson’s character from his 2003 novel titled
                precisely <em><a href="https://en.wikipedia.org/wiki/Pattern_Recognition_(novel)">Pattern
                        Recognition</a></em>, in which advertising consultant Cayce Pollard had an almost superhuman
                ability to make connections and find meanings within the flow of marketing data. In its use of brute
                force computation, AI is indeed capable of achieving goals that can delight, surprise or even shock
                humans: from Amazon’s recommendation algorithms through to the autocomplete function on mobile phones,
                face recognition or even the ability to win at complex board games such as Go. The fuzziness and
                relative narrowness of the definition of “intelligence” notwithstanding, these achievements have led to
                some rather bold claims. The boldest of all is the prediction of an imminent era of singularity, in
                which humans will supposedly merge with algorithms to achieve disembodied (and hopefully immortal)
                intelligence — although, as the recent Netflix series <em>Altered Carbon</em> shows, eternal salvation
                may only be available to the very rich.</p>
            <p>The resurfacing of the hubristic narratives about human futures spurred on by the latest AI research has
                been accompanied by the excavation of the myth of the robot (and its cousins, the android and the
                cyborg) as the human’s other, an intelligent companion who can always turn into an enemy — such as HAL
                9000 from <em>Space Odyssey</em> or the killer robotic dog from season 4 of <em>Black Mirror</em>.
                Popular imagination has thus once again been captured by both salvation narratives and horror stories
                about “them” taking over “us”: eliminating our jobs, conquering our habitat, and killing us all in the
                end.</p>
            <figure><img src="https://cdn-images-1.medium.com/fit/c/196/257/1*NEYvigBpcUABUW3CQjF0dg.png"
                    width="196"><label class="margin-toggle" for="10862164220640835750">&#9997;&#xFE0E;</label><input
                    class="margin-toggle" type="checkbox" id="10862164220640835750"><span class="marginnote"></span>
            </figure>
            <p>Yet such stories, both in their salutary and horror-driven guises, are premised on a rather
                unsophisticated model of the human as a self-enclosed non-technological being, involved in eternal
                battle with <em>tekhnē</em>. However, humans have <em>always</em> been technological, in the sense that
                we have emerged with technology and through our relationship to it, from flint stones used as tools and
                weapons to genetic and cultural algorithms.</p>
            <p>Instead of pitching the human against the machine, shouldn’t we rather see different forms of human
                activity as having <em>always</em> been to some extent artificially intelligent? What if, instead of
                “them” taking over, it is really just <em>us</em> doing it <em>to ourselves</em>? Does it change the
                story in any way? Does it call for some better questions?</p>
            <p>To recognize this shared technological kinship is not to say that all forms of AI are created equal (or
                equally benign), or that they may not have unforeseen consequences. It is rather to make a plea for
                interrogating some of the claims spawned by the dominant AI narrative — and by their intellectual and
                financial backers. This acknowledgement repositions the seemingly eternal narrative of the human’s
                battle against technology as a politico-ethical injunction. The questions that need to be asked concern
                the different modes of life that the currently available AI algorithms enable and disable:</p>
            <ul>
                <li>Whose brainchild (and bodychild) is the AI of today?</li>
                <li>Who and what does AI make life better <em>for</em>?</li>
                <li>Who and what <em>can’t</em> it see?</li>
                <li>What are its own blind spots?</li>
            </ul>
            <p>Storytellers can help us explore the answers to these questions by looking askew at the current claims
                and promises about AI, with their celestial as well as apocalyptic undertones — and by retelling the
                dominant narratives in different genres and different media. Because, as Donna Haraway has poignantly
                highlighted in <em><a href="https://www.dukeupress.edu/staying-with-the-trouble">Staying with the
                        Trouble</a></em>, “It matters what knowledges know knowledges. It matters what relations relate
                relations. It matters what worlds world worlds. It matters what stories tell stories.” Storytelling thus
                may be the first step on the way to responsible AI.</p>
            <blockquote>
                <p><a href="http://www.joannazylinska.net">Joanna Zylinska</a> is Professor of New Media and
                    Communications at Goldsmiths, University of London, an author of seven books on technology, ethics
                    and art, and a photomedia artist. Her latest book is <em><a
                            href="https://www.upress.umn.edu/book-division/books/the-end-of-man">The End of Man: A
                            Feminist Counterapocalypse</a></em> (University of Minnesota Press, 2018).</p>
            </blockquote>
            <blockquote>
                <p><em>Immerse </em>is an initiative of the MIT Open DocLab and The Fledgling Fund. <em>Learn more about
                        our vision for the project </em><a
                        href="https://immerse.news/whats-our-editorial-vision-82d7eeb3e7b9#.2vsd5nxxm">here</a><em>.</em>
                </p>
            </blockquote>
        </section>
    </article>
</body>

</html>